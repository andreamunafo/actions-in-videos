{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data_augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation\n",
    "\n",
    "> This module focuses on having a set of classes to perform the needed data transformations.\n",
    "\n",
    "Some of these transformations are already available in torchvision, for example:\n",
    "\n",
    "`transforms.Resize, transforms.ToTensor(), transforms.Normalize(mean, std)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "import torch\n",
    "\n",
    "from torchvision import transforms\n",
    "from skimage import io, transform\n",
    "\n",
    "from actions_in_videos.dataset_ucf101 import UCF101 \n",
    "from actions_in_videos.avi import AVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']        \n",
    "        \n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w), preserve_range=True)\n",
    "        # for some reason the cv2.resize call fails when used in a DataLoader\n",
    "            \n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "    NOTE: Output does not keep the same aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.            \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, out_ratio=0.7, p_crop=0.5):\n",
    "        self.out_ratio = out_ratio\n",
    "        self.p_crop = p_crop\n",
    "        \n",
    "    def __call__(self, sample):      \n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        curr_h, curr_w = image.shape[:2]\n",
    "        \n",
    "        resize_factor_w = (1-self.out_ratio)*np.random.rand()+self.out_ratio\n",
    "        resize_factor_h = (1-self.out_ratio)*np.random.rand()+self.out_ratio\n",
    "        w1 = int(curr_w*resize_factor_w)\n",
    "        h1 = int(curr_h*resize_factor_h)\n",
    "        w = np.random.randint(curr_w-w1)\n",
    "        h = np.random.randint(curr_h-h1)\n",
    "                \n",
    "        # crop\n",
    "        if np.random.uniform() <= self.p_crop:\n",
    "            image = image[h:(h+h1),w:(w+w1),:]\n",
    "\n",
    "        return {'image': image, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        if type(label) != np.ndarray:\n",
    "            label = np.ndarray(label)\n",
    "            \n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return {'image': torch.from_numpy(image).float(),\n",
    "                'label': torch.from_numpy(label)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Normalize(object):\n",
    "    \"\"\"Normalises an image.\n",
    "        \n",
    "    Args:\n",
    "        mean and std values. Deafult values based on the default pytorch \n",
    "        pretrained ResNet-50 model.      \n",
    "        \n",
    "        old values: \n",
    "        - mean: np.asarray([0.485, 0.456, 0.406]\n",
    "        - std : np.asarray([0.229, 0.224, 0.225]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean = np.asarray([0.433, 0.4045, 0.3776], np.float32),\n",
    "                       std  = np.asarray([0.1519876, 0.14855877, 0.156976], np.float32)):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        ## resnet model was trained on images with mean subtracted\n",
    "        image = image/255.0\n",
    "        \n",
    "        return {'image': (image - self.mean)/self.std,\n",
    "                'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RandomHorizontalFlip(object):\n",
    "    \"\"\"Randomly horizontally flip the image in a sample.  \n",
    "    \n",
    "    Args: prob of flipping the sample\n",
    "    \"\"\"\n",
    "    def __init__(self, p_flip = .5):\n",
    "        self.p = p_flip\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "\n",
    "        if np.random.uniform() <= self.p:\n",
    "            image = cv2.flip(image, 1)  # one is horizontally                   \n",
    "        \n",
    "        return {'image': image, 'label': label}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AddRandomBrightness(object):\n",
    "    \"\"\"Randomly add brightness between a minimum and maximum value.\n",
    "    Saturates if needed. \"\"\"\n",
    "    \n",
    "    def __init__(self, b_offset = 15):\n",
    "        self.brightness = b_offset*2  # brightness +/- b_offset\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, label = sample['image'], sample['label']\n",
    "        \n",
    "        image += np.random.randint(self.brightness+1) - self.brightness/2.0\n",
    "        \n",
    "        #saturates:\n",
    "        image[image>255] = 255.0\n",
    "        image[image<0]   = 0.0\n",
    "        \n",
    "        return {'image': image, 'label': label}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how the classes work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = Rescale(224)\n",
    "crop = RandomCrop(p_crop=1.0)\n",
    "flip = RandomHorizontalFlip(p_flip=1.0)\n",
    "brightness = AddRandomBrightness(15)\n",
    "normalize = Normalize()\n",
    "\n",
    "composed = transforms.Compose([RandomCrop(out_ratio=0.7, p_crop=0.5),\n",
    "                               RandomHorizontalFlip(0.5),\n",
    "                               Rescale(224),\n",
    "                               AddRandomBrightness(15),                               \n",
    "                               Normalize()])\n",
    "\n",
    "tsmf_list = [scale, crop, flip, brightness, normalize, composed]\n",
    "\n",
    "\n",
    "# read the data\n",
    "ucf = UCF101('../data/UCF101/')\n",
    "\n",
    "X, class_names = ucf.getFileList(data_type='train')\n",
    "file_list, labels = X[0], X[1]\n",
    "\n",
    "avi = AVI(file_list[200])\n",
    "label = labels[200]\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "sample = {'image': avi.getRandomFrame(),\n",
    "          'label': label}\n",
    "\n",
    "# plot after applying the transformations\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.subplots_adjust(left=0, right=0.5, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i, tsfrm in enumerate(tsmf_list):\n",
    "    transformed_sample = tsfrm(sample)\n",
    "    \n",
    "    ax = plt.subplot(np.ceil(len(tsmf_list)/2), 2, i + 1)\n",
    "    ax.set_title(type(tsfrm).__name__)\n",
    "    ax.axis('off')\n",
    "    avi.frameShow(transformed_sample['image'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we implement the same transformation but with no labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageRescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If tuple, output is\n",
    "            matched to output_size. If int, smaller of image edges is matched\n",
    "            to output_size keeping aspect ratio the same.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, image):\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w), preserve_range=True)  \n",
    "        # for some reason the cv2.resize call fails when used in a DataLoader\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageRandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "    NOTE: Output does not keep the same aspect ratio.\n",
    "    \n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.            \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, out_ratio=0.7, p_crop=0.5):\n",
    "        self.out_ratio = out_ratio\n",
    "        self.p_crop = p_crop\n",
    "        \n",
    "    def __call__(self, image):              \n",
    "        curr_h, curr_w = image.shape[:2]\n",
    "        \n",
    "        resize_factor_w = (1-self.out_ratio)*np.random.rand()+self.out_ratio\n",
    "        resize_factor_h = (1-self.out_ratio)*np.random.rand()+self.out_ratio\n",
    "        w1 = int(curr_w*resize_factor_w)\n",
    "        h1 = int(curr_h*resize_factor_h)\n",
    "        w = np.random.randint(curr_w-w1)\n",
    "        h = np.random.randint(curr_h-h1)\n",
    "                \n",
    "        # crop\n",
    "        if np.random.uniform() <= self.p_crop:\n",
    "            image = image[h:(h+h1),w:(w+w1),:]\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, image):            \n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        return torch.from_numpy(image).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageNormalize(object):\n",
    "    \"\"\"Normalises an image.\n",
    "        \n",
    "    Args:\n",
    "        mean and std values. Deafult values based on the default pytorch \n",
    "        pretrained ResNet-50 model.      \n",
    "        \n",
    "        old values: \n",
    "        - mean: np.asarray([0.485, 0.456, 0.406]\n",
    "        - std : np.asarray([0.229, 0.224, 0.225]\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mean = np.asarray([0.433, 0.4045, 0.3776], np.float32),\n",
    "                       std  = np.asarray([0.1519876, 0.14855877, 0.156976], np.float32)):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __call__(self, image):\n",
    "        ## resnet model was trained on images with mean subtracted\n",
    "        image = image/255.0        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageRandomHorizontalFlip(object):\n",
    "    \"\"\"Randomly horizontally flip the image in a sample.  \n",
    "    \n",
    "    Args: prob of flipping the sample\n",
    "    \"\"\"\n",
    "    def __init__(self, p_flip = .5):\n",
    "        self.p = p_flip\n",
    "\n",
    "    def __call__(self, image):\n",
    "        if np.random.uniform() <= self.p:\n",
    "            image = cv2.flip(image, 1)  # one is horizontally                   \n",
    "        \n",
    "        return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageAddRandomBrightness(object):\n",
    "    \"\"\"Randomly add brightness between a minimum and maximum value.\n",
    "    Saturates if needed. \"\"\"\n",
    "    \n",
    "    def __init__(self, b_offset = 15):\n",
    "        self.brightness = np.uint8(b_offset*2)  # brightness +/- b_offset\n",
    "        \n",
    "    def __call__(self, image):        \n",
    "        dbright = np.random.randint(self.brightness+1) - self.brightness/2.0\n",
    "        #print('dbright:', dbright)\n",
    "        image = np.float32(image) + dbright\n",
    "        #print('np.max(image)', np.max(image))\n",
    "        #print('np.min(image)', np.min(image))\n",
    "        \n",
    "        #saturates:\n",
    "        image[image>255] = 255.0\n",
    "        image[image<0]   = 0.0\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ImageAddBrightness(object):\n",
    "    \"\"\"Add brightness to an image.\n",
    "    Saturates if needed. \"\"\"\n",
    "    \n",
    "    def __init__(self, b_offset = 15):\n",
    "        self.brightness = b_offset*2  # brightness +/- b_offset\n",
    "        \n",
    "    def __call__(self, image):        \n",
    "        image += image + self.brightness\n",
    "       # print('np.max(image)', np.max(image))\n",
    "       # print('np.min(image)', np.min(image))\n",
    "        #saturates:\n",
    "        image[image>255] = 255.0\n",
    "        image[image<0]   = 0.0\n",
    "        \n",
    "        return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how the classes work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = ImageRescale(224)\n",
    "crop = ImageRandomCrop(p_crop=1.0)\n",
    "flip = ImageRandomHorizontalFlip(p_flip=1.0)\n",
    "brightness = ImageAddRandomBrightness(15)\n",
    "normalize = ImageNormalize()\n",
    "\n",
    "composed = transforms.Compose([ImageRandomCrop(out_ratio=0.7, p_crop=0.5),\n",
    "                               ImageRandomHorizontalFlip(0.5),\n",
    "                               ImageRescale(224),\n",
    "                               ImageAddRandomBrightness(15),                               \n",
    "                               ImageNormalize()])\n",
    "\n",
    "tsmf_list = [scale, crop, flip, brightness, normalize, composed]\n",
    "\n",
    "\n",
    "# read the data\n",
    "ucf = UCF101('../data/UCF101/')\n",
    "\n",
    "X, class_names = ucf.getFileList(data_type='train')\n",
    "file_list, labels = X[0], X[1]\n",
    "\n",
    "avi = AVI(file_list[200])\n",
    "label = labels[200]\n",
    "\n",
    "# Apply each of the above transforms on sample.\n",
    "image = avi.getRandomFrame()\n",
    "\n",
    "# plot after applying the transformations\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.subplots_adjust(left=0, right=0.5, bottom=0, top=0.5, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i, tsfrm in enumerate(tsmf_list):\n",
    "    transformed_sample = tsfrm(image)\n",
    "    \n",
    "    ax = plt.subplot(np.ceil(len(tsmf_list)/2), 2, i + 1)\n",
    "    ax.set_title(type(tsfrm).__name__)\n",
    "    ax.axis('off')\n",
    "    avi.frameShow(transformed_sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
