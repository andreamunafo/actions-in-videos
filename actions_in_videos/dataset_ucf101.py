# AUTOGENERATED! DO NOT EDIT! File to edit: dev/01_dataset_ucf101.ipynb (unless otherwise specified).

__all__ = ['UCF101', 'SingleFrameDataset', 'BatchShower']

# Cell
import numpy as np
import pathlib
import matplotlib.pyplot as plt

from torch.utils.data import Dataset, DataLoader
from torchvision import utils
import torchvision.transforms as transforms
import torch

from .avi import AVI

# Cell
class UCF101:
    def __init__(self, base_directory=''):
        """
        Args:
          base_directory: main data folder (e.g. ../data/UCF101)
        """
        self.base_directory = pathlib.Path(base_directory)

    def getFileList(self, data_type='train', remove_classname = False):
        """
        This function uses a text file provided with the dataset
        which lists all of the relative paths for the videos for the train/test split.

        Args:
          data_type: 'train' | 'test'
          remove_classname: if True does not include the class name in the filenames.

        Returns:
          X is a tuple.
             The first element is a numpy array with the absolute
               filepaths for the videos for training.
             The second element is a numpy array of class indices (0-100).
          class_names is a list of the action categories.

        """

        base_directory = self.base_directory

        #print(f'[getFileList] Reading data from: {base_directory}')

        # action class labels
        class_file = open(base_directory/'annotations/ucfTrainTestlist/classInd.txt','r')
        lines = class_file.readlines()
        lines = [line.split(' ')[1].strip() for line in lines]
        class_file.close()
        class_names = np.asarray(lines)

        if data_type == 'train':
            # training data
            train_file = open(base_directory/'annotations/ucfTrainTestlist/trainlist01.txt','r')
            lines = train_file.readlines()
            if remove_classname:
                filenames = ['/UCF-101/' + line.split(' ')[0].split('/')[1] for line in lines]
            else:
                filenames = ['/UCF-101/' + line.split(' ')[0] for line in lines]
            y_train = [int(line.split(' ')[1].strip())-1 for line in lines]
            y_train = np.asarray(y_train)
            filenames = [base_directory.as_posix() + filename for filename in filenames]
            train_file.close()
            train = (np.asarray(filenames),y_train)

            X = train

        else:
            # testing data
            test_file = open(base_directory/'annotations/ucfTrainTestlist/testlist01.txt','r')
            lines = test_file.readlines()
            filenames = ['/UCF-101/' + line.split(' ')[0].strip() for line in lines]
            classnames = [filename.split('/')[2] for filename in filenames]

            if remove_classname:
                # remove the class name from the filename if needed.
                filenames = ['/UCF-101/' + line.split(' ')[0].split('/')[1].strip() for line in lines]

            y_test = [np.where(classname == class_names)[0][0] for classname in classnames]
            y_test = np.asarray(y_test)
            filenames = [base_directory.as_posix() + filename for filename in filenames]
            test_file.close()
            test = (np.asarray(filenames),y_test)

            X = test

        #print('[getFileList] Done.')
        return X, class_names


    def downloadData(self):
        """
        Downloads all zip files of the UCF101 dataset.
        """

        target_dir = self.base_directory
        print(f'[downloadData] 1/2 Beginning file download to {target_dir}')

        compressed_dir = pathlib.Path(target_dir + '/compressed')
        compressed_dir.mkdir(parents=True, exist_ok=True)

        annotations_dir = pathlib.Path(target_dir + '/annotations')
        annotations_dir.mkdir(parents=True, exist_ok=True)

        destination_dir = pathlib.Path(target_dir + '/UCF-101')
        destination_dir.mkdir(parents=True, exist_ok=True)

        # download annotations for action recognition
        if pathlib.Path(compressed_dir/'UCF101TrainTestSplits-RecognitionTask.zip').exists():
            print ("[downloadData]File UCF101TrainTestSplits-RecognitionTask.zip exists.")
        else:
            annotation_url = 'https://www.crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip'
            filename = wget.download(annotation_url, out=compressed_dir.as_posix(), bar=wget.bar_adaptive)
            print(f'[downloadData]File downloaded to {filename}')

        if pathlib.Path(compressed_dir/'UCF101TrainTestSplits-DetectionTask.zip').exists():
            print ("[downloadData]File UCF101TrainTestSplits-DetectionTask.zip exists.")
        else:
            # download annotations for action detection
            annotation_url = 'https://www.crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-DetectionTask.zip'
            filename =wget.download(annotation_url, out=compressed_dir.as_posix(), bar=wget.bar_adaptive)
            print(f'[downloadData]File downloaded to {filename}')

        # download videos
        if pathlib.Path(compressed_dir/'UCF101.rar').exists():
            print ("[downloadData]File UCF101.rar exists.")
        else:
            video_url = 'https://www.crcv.ucf.edu/data/UCF101/UCF101.rar'
            filename =wget.download(video_url, out=compressed_dir.as_posix(), bar=wget.bar_adaptive)
            print(f'[downloadData]File downloaded to {filename}')

        print('[downloadData] Done.\n')

    def extractData(self):
        """
        Extracts all zip files of the UCF101 dataset.
        It does system calls and it needs unrar (apt-get install unrar-free)
        """

        target_dir = self.base_directory
        print('[extractData] Extracting data...')

        target_dir = pathlib.Path(target_dir)

        compressed_dir = pathlib.Path(target_dir/'compressed')
        compressed_dir.mkdir(parents=True, exist_ok=True)

        annotations_dir = pathlib.Path(target_dir/'annotations')
        annotations_dir.mkdir(parents=True, exist_ok=True)

        destination_dir = pathlib.Path(target_dir/'UCF-101')
        destination_dir.mkdir(parents=True, exist_ok=True)

        try:
            bash_cmd = 'unrar ' + target_dir.as_posix() + '/UCF101.rar' + ' ' + target_dir.as_posix() + '/UCF-101'
            print(bash_cmd)
            process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
            output, error = process.communicate()
            print(output)
        except Exception as e:
            print(e)
        print()

        bash_cmd = 'cp ' + target_dir.as_posix() + '/compressed/UCF101TrainTestSplits-RecognitionTask.zip ' + annotations_dir.as_posix() + '/UCF101TrainTestSplits-RecognitionTask.zip'
        print(bash_cmd)
        process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
        output, error = process.communicate()
        if len(output) > 0: print(output)
        if len(error) > 0: print(error)
        print()

        bash_cmd = 'unzip ' + annotations_dir .as_posix() + '/UCF101TrainTestSplits-RecognitionTask.zip -d ' + annotations_dir.as_posix()
        print(bash_cmd)
        process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
        output, error = process.communicate()
        if len(output) > 0: print(output)
        if len(error) > 0: print(error)
        print()

        bash_cmd = 'cp ' + target_dir.as_posix() + '/compressed/UCF101TrainTestSplits-DetectionTask.zip ' + annotations_dir.as_posix() + '/UCF101TrainTestSplits-DetectionTask.zip'
        print(bash_cmd)
        process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
        output, error = process.communicate()
        if len(output) > 0: print(output)
        if len(error) > 0: print(error)
        print()

        bash_cmd = 'unzip ' + annotations_dir.as_posix() + '/UCF101TrainTestSplits-DetectionTask.zip -d ' + annotations_dir.as_posix()
        print(bash_cmd)
        process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
        output, error = process.communicate()
        if len(output) > 0: print(output)
        if len(error) > 0: print(error)
        print()

        bash_cmd = 'rm ' + target_dir.as_posix() + '/annotations/*.zip'
        print(bash_cmd)
        process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
        output, error = process.communicate()
        if len(output) > 0: print(output)
        if len(error) > 0: print(error)

        print()
        print('[extractData] Done.')

# Cell
class SingleFrameDataset(Dataset):
    """Single frame dataset for the UCF101."""

    def __init__(self, dataset_path, training=True, transform=None):
        """
        Args:
            file_list: list of files as a numpy array.
            labels: one entry per filename in the list of files as a numpy array.
            train: flag to say whether train or test dataset is used.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.training = True
        ucf = UCF101(dataset_path)

        X, class_names = ucf.getFileList(data_type=['train' if training else 'test'])
        self.file_list, self.labels = X[0], X[1]
        self.class_names = class_names
        self.num_classes = len(self.class_names)
        self.transform = transform

    def getClassName(self, idx):
        return self.class_names[idx]

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        video_list = self.file_list[idx]
        avi = AVI(video_list)

        frame = avi.getRandomFrame()

        label = self.labels[idx]
        label = np.array([label])

        if self.transform:
#            frame = frame.transpose(2,0,1)
            frame = self.transform(frame)

        return frame, label


# Cell
class BatchShower:
    def __init__(self, dl):
        self.dl = dl

    def showBatch(self, idx):
        """Loops through the dataloader and shows only one batch (idx)"""
        assert idx >= 0 and idx <= np.floor(len(self.dl.dataset)/self.dl.batch_size), "selected batch index out of batch size range: [0, %d]" % np.floor(len(self.dl.dataset)/self.dl.batch_size)

        for i_batch, sample_batched in enumerate(self.dl):
#            print(i_batch, sample_batched[0].size())
            # observe 4th batch and stop.
            if i_batch == idx:
                plt.figure(figsize=(10,10))
                image, label = sample_batched[0], sample_batched[1]
                class_name = self.dl.dataset.getClassName(sample_batched[1])
                self.showThisBatch(image, label)
                print(class_name.tolist())
                plt.axis('off')
                plt.ioff()
                plt.show()
                break


    def showThisBatch(self, images_batch, labels_batch):
        """Show image for a batch of samples.
        Must be tensors of size (bs x w x h x channels).
        """
        batch_size = len(images_batch)
        im_size = images_batch.size()

        ncols = int(np.ceil(np.sqrt(batch_size)))
        for i in range(batch_size):
            ax = plt.subplot(ncols, ncols, i+1)
            if type(images_batch[i]) == torch.Tensor:
                frame = images_batch[i].data.numpy()
                frame = frame/255.

            if frame.shape[0] <= 3:
                frame = frame.transpose(1, 2, 0)

            if np.min(frame) <= 0:
                frame += np.mean(frame)
                frame[frame<0] = 0
            if np.max(frame) <= 1:
                frame = frame*255
                frame[frame>255] = 255

            plt.imshow(frame)
#           plt.tight_layout()
            ax.axis('off')
