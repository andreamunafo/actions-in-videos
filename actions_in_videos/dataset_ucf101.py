# AUTOGENERATED! DO NOT EDIT! File to edit: dev/01_dataset_ucf101.ipynb (unless otherwise specified).

__all__ = ['UCF101', 'SingleFrameDataset', 'BatchShower', 'SequenceDataset', 'SequenceBatchShower']

# Cell
import numpy as np
import pathlib
import matplotlib.pyplot as plt

from torch.utils.data import Dataset, DataLoader
from torchvision import utils
import torchvision.transforms as transforms
import torch

from .avi import AVI

# Cell
class UCF101:
    def __init__(self, base_directory=''):
        """
        Args:
          base_directory: main data folder (e.g. ../data/UCF101)
        """
        self.base_directory = pathlib.Path(base_directory)

    def getFileList(self, data_type='train', remove_classname = False):
        """
        This function uses a text file provided with the dataset
        which lists all of the relative paths for the videos for the train/test split.

        Args:
          data_type: 'train' | 'test'
          remove_classname: if True does not include the class name in the filenames.

        Returns:
          X is a tuple.
             The first element is a numpy array with the absolute
               filepaths for the videos for training.
             The second element is a numpy array of class indices (0-100).
          class_names is a list of the action categories.

        """

        base_directory = self.base_directory

        #print(f'[getFileList] Reading data from: {base_directory}')

        # action class labels
        class_file = open(base_directory/'annotations/ucfTrainTestlist/classInd.txt','r')
        lines = class_file.readlines()
        lines = [line.split(' ')[1].strip() for line in lines]
        class_file.close()
        class_names = np.asarray(lines)

        if data_type == 'train':
            # training data
            train_file = open(base_directory/'annotations/ucfTrainTestlist/trainlist01.txt','r')
            lines = train_file.readlines()
            if remove_classname:
                filenames = ['/UCF-101/' + line.split(' ')[0].split('/')[1] for line in lines]
            else:
                filenames = ['/UCF-101/' + line.split(' ')[0] for line in lines]
            y_train = [int(line.split(' ')[1].strip())-1 for line in lines]
            y_train = np.asarray(y_train)
            filenames = [base_directory.as_posix() + filename for filename in filenames]
            train_file.close()
            train = (np.asarray(filenames),y_train)

            X = train
            print('Number of training files:', len(X[0]))

        else:
            # testing data
            test_file = open(base_directory/'annotations/ucfTrainTestlist/testlist01.txt','r')
            lines = test_file.readlines()
            filenames = ['/UCF-101/' + line.split(' ')[0].strip() for line in lines]
            classnames = [filename.split('/')[2] for filename in filenames]

            if remove_classname:
                # remove the class name from the filename if needed.
                filenames = ['/UCF-101/' + line.split(' ')[0].split('/')[1].strip() for line in lines]

            y_test = [np.where(classname == class_names)[0][0] for classname in classnames]
            y_test = np.asarray(y_test)
            filenames = [base_directory.as_posix() + filename for filename in filenames]
            test_file.close()
            test = (np.asarray(filenames),y_test)

            X = test
            print('Number of validation files:', len(X[0]))
        #print('[getFileList] Done.')
        return X, class_names


    def downloadData(self):
        """
        Downloads all zip files of the UCF101 dataset.
        """

        target_dir = self.base_directory
        print(f'[downloadData] 1/2 Beginning file download to {target_dir}')

        compressed_dir = pathlib.Path(target_dir + '/compressed')
        compressed_dir.mkdir(parents=True, exist_ok=True)

        annotations_dir = pathlib.Path(target_dir + '/annotations')
        annotations_dir.mkdir(parents=True, exist_ok=True)

        destination_dir = pathlib.Path(target_dir + '/UCF-101')
        destination_dir.mkdir(parents=True, exist_ok=True)

        # download annotations for action recognition
        if pathlib.Path(compressed_dir/'UCF101TrainTestSplits-RecognitionTask.zip').exists():
            print ("[downloadData]File UCF101TrainTestSplits-RecognitionTask.zip exists.")
        else:
            annotation_url = 'https://www.crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-RecognitionTask.zip'
            filename = wget.download(annotation_url, out=compressed_dir.as_posix(), bar=wget.bar_adaptive)
            print(f'[downloadData]File downloaded to {filename}')

        if pathlib.Path(compressed_dir/'UCF101TrainTestSplits-DetectionTask.zip').exists():
            print ("[downloadData]File UCF101TrainTestSplits-DetectionTask.zip exists.")
        else:
            # download annotations for action detection
            annotation_url = 'https://www.crcv.ucf.edu/data/UCF101/UCF101TrainTestSplits-DetectionTask.zip'
            filename =wget.download(annotation_url, out=compressed_dir.as_posix(), bar=wget.bar_adaptive)
            print(f'[downloadData]File downloaded to {filename}')

        # download videos
        if pathlib.Path(compressed_dir/'UCF101.rar').exists():
            print ("[downloadData]File UCF101.rar exists.")
        else:
            video_url = 'https://www.crcv.ucf.edu/data/UCF101/UCF101.rar'
            filename =wget.download(video_url, out=compressed_dir.as_posix(), bar=wget.bar_adaptive)
            print(f'[downloadData]File downloaded to {filename}')

        print('[downloadData] Done.\n')

    def extractData(self):
        """
        Extracts all zip files of the UCF101 dataset.
        It does system calls and it needs unrar (apt-get install unrar-free)
        """

        target_dir = self.base_directory
        print('[extractData] Extracting data...')

        target_dir = pathlib.Path(target_dir)

        compressed_dir = pathlib.Path(target_dir/'compressed')
        compressed_dir.mkdir(parents=True, exist_ok=True)

        annotations_dir = pathlib.Path(target_dir/'annotations')
        annotations_dir.mkdir(parents=True, exist_ok=True)

        destination_dir = pathlib.Path(target_dir/'UCF-101')
        destination_dir.mkdir(parents=True, exist_ok=True)

        try:
            bash_cmd = 'unrar ' + target_dir.as_posix() + '/UCF101.rar' + ' ' + target_dir.as_posix() + '/UCF-101'
            print(bash_cmd)
            process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
            output, error = process.communicate()
            print(output)
        except Exception as e:
            print(e)
        print()

        bash_cmd = 'cp ' + target_dir.as_posix() + '/compressed/UCF101TrainTestSplits-RecognitionTask.zip ' + annotations_dir.as_posix() + '/UCF101TrainTestSplits-RecognitionTask.zip'
        print(bash_cmd)
        process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
        output, error = process.communicate()
        if len(output) > 0: print(output)
        if len(error) > 0: print(error)
        print()

        bash_cmd = 'unzip ' + annotations_dir .as_posix() + '/UCF101TrainTestSplits-RecognitionTask.zip -d ' + annotations_dir.as_posix()
        print(bash_cmd)
        process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
        output, error = process.communicate()
        if len(output) > 0: print(output)
        if len(error) > 0: print(error)
        print()

        bash_cmd = 'cp ' + target_dir.as_posix() + '/compressed/UCF101TrainTestSplits-DetectionTask.zip ' + annotations_dir.as_posix() + '/UCF101TrainTestSplits-DetectionTask.zip'
        print(bash_cmd)
        process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
        output, error = process.communicate()
        if len(output) > 0: print(output)
        if len(error) > 0: print(error)
        print()

        bash_cmd = 'unzip ' + annotations_dir.as_posix() + '/UCF101TrainTestSplits-DetectionTask.zip -d ' + annotations_dir.as_posix()
        print(bash_cmd)
        process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
        output, error = process.communicate()
        if len(output) > 0: print(output)
        if len(error) > 0: print(error)
        print()

        bash_cmd = 'rm ' + target_dir.as_posix() + '/annotations/*.zip'
        print(bash_cmd)
        process = subprocess.Popen(bash_cmd.split(), stdout=subprocess.PIPE)
        output, error = process.communicate()
        if len(output) > 0: print(output)
        if len(error) > 0: print(error)

        print()
        print('[extractData] Done.')

# Cell
class SingleFrameDataset(Dataset):
    """Single frame dataset for the UCF101."""

    def __init__(self, dataset_path, training=True, transform=None):
        """
        Args:
            file_list: list of files as a numpy array.
            labels: one entry per filename in the list of files as a numpy array.
            train: flag to say whether train or test dataset is used.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.training = True
        ucf = UCF101(dataset_path)

        X, class_names = ucf.getFileList(data_type='train' if training else 'test')
        self.file_list, self.labels = X[0], X[1]
        self.class_names = class_names
        self.num_classes = len(self.class_names)
        self.transform = transform

    def getClassName(self, idx):
        return self.class_names[idx]

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()

        video_list = self.file_list[idx]
        #video_list = self.file_list[idx % len(self)] # wraps up if an out of index idx is used.
        avi = AVI(video_list)

        frame = avi.getRandomFrame()

        label = self.labels[idx]
        label = np.array([label])

        if self.transform:
#            frame = frame.transpose(2,0,1)
            frame = self.transform(frame)

        return frame, label


# Cell
class BatchShower:
    def __init__(self, dl):
        self.dl = dl

    def showBatch(self, idx, scale=1):
        """Loops through the dataloader and shows only one batch (idx)"""
        assert idx >= 0 and idx <= np.floor(len(self.dl.dataset)/self.dl.batch_size), "selected batch index out of batch size range: [0, %d]" % np.floor(len(self.dl.dataset)/self.dl.batch_size)

        for i_batch, sample_batched in enumerate(self.dl):
#            print(i_batch, sample_batched[0].size())
#             observe the idx-th batch and stop
            if i_batch == idx:
                plt.figure(figsize=(10,10))
                image, label = sample_batched[0], sample_batched[1]
                class_name = self.dl.dataset.getClassName(sample_batched[1])
                self.showThisBatch(image, label, scale)
                print(class_name.tolist())
                plt.axis('off')
                plt.ioff()
                plt.show()
                break


    def showThisBatch(self, images_batch, labels_batch, scale=1):
        """Show image for a batch of samples.
        Must be tensors of size (bs x w x h x channels).
        """
        batch_size = len(images_batch)
        im_size = images_batch.size()

        ncols = int(np.ceil(np.sqrt(batch_size)))
        for i in range(batch_size):
            ax = plt.subplot(ncols, ncols, i+1)
            if type(images_batch[i]) == torch.Tensor:
                frame = images_batch[i].data.numpy()
                frame = frame/255.

            if frame.shape[0] <= 3:
                frame = frame.transpose(1, 2, 0)

            frame_v_mean = np.mean(frame)

            frame = scale*frame

            frame[frame<0] = 0
            if np.mean(frame) < 2:
                frame[frame>1] = 1
            else:
                frame[frame>255] = 255

            plt.imshow(frame)
#           plt.tight_layout()
            ax.axis('off')


# Cell
class SequenceDataset(Dataset):
    """Sequence based dataset for the UCF101.

    Output is of shape:
        seq_len, H, W, C

    Note that when this is passed onto a DataLoader with toTensor() transform, it changes its shape to:
        batch_size, seq_length, C, H, W

    """

    def __init__(self, dataset_path, sequence_length, sample_interval=1, training=True, transform=None):
        """
        Args:
            file_list: list of files as a numpy array.
            labels: one entry per filename in the list of files as a numpy array.
            train: flag to say whether train or test dataset is used.
            transform (callable, optional): Optional transform to be applied
                on a sample.
        """
        self.training = True
        self.sequence_length = sequence_length
        self.sample_interval = sample_interval

        ucf = UCF101(dataset_path)

        X, class_names = ucf.getFileList(data_type='train' if training else 'test')
        self.file_list, self.labels = X[0], X[1]
        self.class_names = class_names
        self.num_classes = len(self.class_names)
        self.transform = transform

    def getClassName(self, idx):
        return self.class_names[idx]

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):
        """

        returns:
        - sequence: list of frames of length self.sequence_length
        """
        if torch.is_tensor(idx):
            idx = idx.tolist()

        #video_list = self.file_list[idx]
        video_list = self.file_list[idx % len(self)] # wraps up if an out of index idx is used.
        avi = AVI(video_list, verbose=False)  # set verbose to True might help debugging.

        frames = avi.getRandomSequence(self.sequence_length, self.sample_interval)
        # frames is a numpy matrix of shape seq_len, H, W, C

        label = self.labels[idx]
        label = np.array([label])

        # Extract frames as tensors
        image_sequence = []

        #image_sequence = torch.stack(image_sequence)
        #     frame = frame.transpose(2,0,1)

        if self.transform:
            sequence = None
            for i, frame in enumerate(frames):
                frame = self.transform(frame)  # here frame might be a tensor
                if sequence is None:
                    # we still need to allocate it.
                    sequence = np.zeros(np.array(np.append(np.array([self.sequence_length]), np.array(frame.shape))))
                sequence[i,:,:,:] = frame
            frames = sequence
#         frame = np.asarray(frame)
#         frame = frame.transpose(3,0,1,2)
#         if type(frame) == torch.Tensor:
#             sequence = torch.stack(sequence)

        return frames, label


# Cell
class SequenceBatchShower:
    def __init__(self, dl, fig_size=5):
        self.dl = dl
        self.fig_size = fig_size

    def showBatch(self, idx, scale=1, permuteToImg=None):
        """Loops through the dataloader and shows only one batch (idx).
        Args:
        - idx: batch number to show
        - scale: accounts for different normalisation constants
        - permuteToImg: let you change the axis of your image to be shown using imshow."""
        assert idx >= 0 and idx <= np.floor(len(self.dl.dataset)/self.dl.batch_size), "selected batch index out of batch size range: [0, %d]" % np.floor(len(self.dl.dataset)/self.dl.batch_size)

        for i_batch, sample_batched in enumerate(self.dl):
            # print(i_batch, sample_batched[0].shape)
            # observe the idx-th batch and stop
            if i_batch == idx:
                plt.figure(figsize=(10,10))
                sequence, label = sample_batched[0], sample_batched[1]

                #print(torch.min(sequence), torch.max(sequence))

                class_name = self.dl.dataset.getClassName(sample_batched[1])
                self.showThisBatch(sequence, label, scale, permuteToImg)
                print(class_name.tolist())
                plt.axis('off')
                plt.ioff()
                plt.show()
                break


    def showThisBatch(self, sequence_batch, labels_batch, scale=1, permuteToImg=None):
        """Show a sequence of images for a batch of samples.
        Must be tensors of size (bs x seq_len x w x h x channels).
        """
        batch_size = len(sequence_batch)
        ncols = int(np.ceil(np.sqrt(batch_size)))
        for i in range(batch_size):
            fig = plt.figure(figsize=(self.fig_size,self.fig_size)); # ax = plt.subplot(ncols, ncols, i+1)
            if permuteToImg is not None and len(permuteToImg)>0:
                one_sequence = sequence_batch[i].permute(permuteToImg).numpy()
            else:
                one_sequence = sequence_batch[i].numpy() # I need seq_len x H x W x C here (e.g. .permute(0,2,3,1) corresponds to .transpose())
            AVI.sequenceShow(one_sequence)
            for a in fig.axes:
                a.axis('off')
